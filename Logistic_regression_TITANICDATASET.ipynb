{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.drop(\"Cabin\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex= pd.get_dummies(titanic_data['Sex'], drop_first=True)\n",
    "embark= pd.get_dummies(titanic_data['Embarked'], drop_first=True)\n",
    "pcls= pd.get_dummies(titanic_data['Pclass'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = pd.concat([titanic_data, sex, embark, pcls], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Survived   Age  SibSp  Parch      Fare  male  Q  S  2  3\n",
      "0           0  22.0      1      0    7.2500     1  0  1  0  1\n",
      "1           1  38.0      1      0   71.2833     0  0  0  0  0\n",
      "2           1  26.0      0      0    7.9250     0  0  1  0  1\n",
      "3           1  35.0      1      0   53.1000     0  0  1  0  0\n",
      "4           0  35.0      0      0    8.0500     1  0  1  0  1\n",
      "6           0  54.0      0      0   51.8625     1  0  1  0  0\n",
      "7           0   2.0      3      1   21.0750     1  0  1  0  1\n",
      "8           1  27.0      0      2   11.1333     0  0  1  0  1\n",
      "9           1  14.0      1      0   30.0708     0  0  0  1  0\n",
      "10          1   4.0      1      1   16.7000     0  0  1  0  1\n",
      "11          1  58.0      0      0   26.5500     0  0  1  0  0\n",
      "12          0  20.0      0      0    8.0500     1  0  1  0  1\n",
      "13          0  39.0      1      5   31.2750     1  0  1  0  1\n",
      "14          0  14.0      0      0    7.8542     0  0  1  0  1\n",
      "15          1  55.0      0      0   16.0000     0  0  1  1  0\n",
      "16          0   2.0      4      1   29.1250     1  1  0  0  1\n",
      "18          0  31.0      1      0   18.0000     0  0  1  0  1\n",
      "20          0  35.0      0      0   26.0000     1  0  1  1  0\n",
      "21          1  34.0      0      0   13.0000     1  0  1  1  0\n",
      "22          1  15.0      0      0    8.0292     0  1  0  0  1\n",
      "23          1  28.0      0      0   35.5000     1  0  1  0  0\n",
      "24          0   8.0      3      1   21.0750     0  0  1  0  1\n",
      "25          1  38.0      1      5   31.3875     0  0  1  0  1\n",
      "27          0  19.0      3      2  263.0000     1  0  1  0  0\n",
      "30          0  40.0      0      0   27.7208     1  0  0  0  0\n",
      "33          0  66.0      0      0   10.5000     1  0  1  1  0\n",
      "34          0  28.0      1      0   82.1708     1  0  0  0  0\n",
      "35          0  42.0      1      0   52.0000     1  0  1  0  0\n",
      "37          0  21.0      0      0    8.0500     1  0  1  0  1\n",
      "38          0  18.0      2      0   18.0000     0  0  1  0  1\n",
      "..        ...   ...    ...    ...       ...   ... .. .. .. ..\n",
      "856         1  45.0      1      1  164.8667     0  0  1  0  0\n",
      "857         1  51.0      0      0   26.5500     1  0  1  0  0\n",
      "858         1  24.0      0      3   19.2583     0  0  0  0  1\n",
      "860         0  41.0      2      0   14.1083     1  0  1  0  1\n",
      "861         0  21.0      1      0   11.5000     1  0  1  1  0\n",
      "862         1  48.0      0      0   25.9292     0  0  1  0  0\n",
      "864         0  24.0      0      0   13.0000     1  0  1  1  0\n",
      "865         1  42.0      0      0   13.0000     0  0  1  1  0\n",
      "866         1  27.0      1      0   13.8583     0  0  0  1  0\n",
      "867         0  31.0      0      0   50.4958     1  0  1  0  0\n",
      "869         1   4.0      1      1   11.1333     1  0  1  0  1\n",
      "870         0  26.0      0      0    7.8958     1  0  1  0  1\n",
      "871         1  47.0      1      1   52.5542     0  0  1  0  0\n",
      "872         0  33.0      0      0    5.0000     1  0  1  0  0\n",
      "873         0  47.0      0      0    9.0000     1  0  1  0  1\n",
      "874         1  28.0      1      0   24.0000     0  0  0  1  0\n",
      "875         1  15.0      0      0    7.2250     0  0  0  0  1\n",
      "876         0  20.0      0      0    9.8458     1  0  1  0  1\n",
      "877         0  19.0      0      0    7.8958     1  0  1  0  1\n",
      "879         1  56.0      0      1   83.1583     0  0  0  0  0\n",
      "880         1  25.0      0      1   26.0000     0  0  1  1  0\n",
      "881         0  33.0      0      0    7.8958     1  0  1  0  1\n",
      "882         0  22.0      0      0   10.5167     0  0  1  0  1\n",
      "883         0  28.0      0      0   10.5000     1  0  1  1  0\n",
      "884         0  25.0      0      0    7.0500     1  0  1  0  1\n",
      "885         0  39.0      0      5   29.1250     0  1  0  0  1\n",
      "886         0  27.0      0      0   13.0000     1  0  1  1  0\n",
      "887         1  19.0      0      0   30.0000     0  0  1  0  0\n",
      "889         1  26.0      0      0   30.0000     1  0  0  0  0\n",
      "890         0  32.0      0      0    7.7500     1  1  0  0  1\n",
      "\n",
      "[712 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "titanic_data.drop([\"Pclass\", \"Sex\", \"Embarked\", \"PassengerId\", \"Name\", \"Ticket\"], axis=1, inplace=True)\n",
    "print(titanic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic_data.drop(\"Survived\", axis=1)\n",
    "Y = titanic_data[\"Survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Namit\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.81      0.83      0.82       126\\n           1       0.75      0.72      0.73        88\\n\\n   micro avg       0.79      0.79      0.79       214\\n   macro avg       0.78      0.77      0.78       214\\nweighted avg       0.78      0.79      0.78       214\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[105,  21],\n",
       "       [ 25,  63]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
